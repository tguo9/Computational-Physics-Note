{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics\n",
    "\n",
    "## 1. PCA Applied to Face Images and \"Whitening\" \n",
    "## 2. PCA and SVM on Face Recognition\n",
    "## 3. The Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "''' Initial Imports'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* \n",
    "# Place the data set on google drive \n",
    "# for some reason, it takes a long time to download \n",
    "# the data. \n",
    "# \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n",
    "\n",
    "## To Downloading Faces (233MB)\n",
    "\n",
    "## (This takes a while and you should start now):\n",
    "\n",
    "http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to read the image file /Users/Tao/scikit_learn_data/lfw_home/lfw_funneled/George_W_Bush/George_W_Bush_0358.jpg, Please make sure that libjpeg is installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f4a0bf715d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Download the data, if not already on disk and load it as numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlfw_people\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_lfw_people\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_faces_per_person\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m                                        \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# introspect the images arrays to find the shapes (for plotting)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/datasets/lfw.py\u001b[0m in \u001b[0;36mfetch_lfw_people\u001b[0;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing)\u001b[0m\n\u001b[1;32m    333\u001b[0m     faces, target, target_names = load_func(\n\u001b[1;32m    334\u001b[0m         \u001b[0mdata_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         min_faces_per_person=min_faces_per_person, color=color, slice_=slice_)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;31m# pack the results as a Bunch instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/datasets/lfw.py\u001b[0m in \u001b[0;36m_fetch_lfw_people\u001b[0;34m(data_folder_path, slice_, color, resize, min_faces_per_person)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# shuffle the faces with a deterministic RNG scheme to avoid having\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/datasets/lfw.py\u001b[0m in \u001b[0;36m_load_imgs\u001b[0;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[1;32m    186\u001b[0m             raise RuntimeError(\"Failed to read the image file %s, \"\n\u001b[1;32m    187\u001b[0m                                \u001b[0;34m\"Please make sure that libjpeg is installed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                                % file_path)\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to read the image file /Users/Tao/scikit_learn_data/lfw_home/lfw_funneled/George_W_Bush/George_W_Bush_0358.jpg, Please make sure that libjpeg is installed"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sklearn face data base\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "\n",
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, \\\n",
    "                                       resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "print('height and width of images:', h, w)\n",
    "\n",
    "# The images in X have been collapsed into a 1D array\n",
    "# just like for the handwritten digits\n",
    "X = lfw_people.data\n",
    "\n",
    "# X.shape[0] tells you the number of images (faces);\n",
    "# this is the same as n_samples ahove\n",
    "# X.shape[1] gives the number of pixels for each image\n",
    "# or, \"features\"\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "\n",
    "# the label/target to predict is the id of the person -- y is an integer\n",
    "y = lfw_people.target\n",
    "# target_names are actually names\n",
    "target_names = lfw_people.target_names\n",
    "print('target_names.shape', target_names.shape)\n",
    "print('target_names', target_names)\n",
    "\n",
    "# n_classes gives the number of people \n",
    "# Different from the number of faces (n_samples)!!\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples (number of faces): {0}\".format(n_samples))\n",
    "# n_features = 1850, which is 50x37, the dimension of the images.\n",
    "print(\"n_features (number of pixels): {0}\".format(n_features))\n",
    "print(\"n_classes (number of people): {0}\".format(n_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Whitening\"\n",
    "\n",
    "## Breakout Exercise:\n",
    "\n",
    "- ## Do PCA on the first 500 images.  Use only 4 components\n",
    "- ## Print out the PCA components (eigenvectors)\n",
    "- ## Print out the PCA variances (eigenvalues)\n",
    "- ## Calculate yourself the variance of along the 0th and 1st PCA axes\n",
    "\n",
    "## Turn on whitening in your PCA instantiation: \n",
    "\n",
    "          whiten = True\n",
    "          \n",
    "## Run the cell again -- can you tell what changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussing the solution\n",
    "\n",
    "- ### The importance of whiten = True\n",
    "    \n",
    "- ### To understand why this helps: \n",
    "\n",
    "    ### Imagine just doing this with just 2 PCA components.  With whitening, in that 2D PCA space, the variance in each PCA direction is 1.  Then you expect to see clusters that are similar in extent in either direction -- meaning they would apear more circular.  This makes it easier to draw boundaries between clusters.\n",
    "\n",
    "- ### This is a helpful resource \n",
    "\n",
    "    ### To see what whitening does:\n",
    "\n",
    "    ### From http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/\n",
    "\n",
    "    ### Look under the Section \"Whitening\", subsection \"2D example\"\n",
    "    \n",
    "   ### Can plot the data in the 2D space of the first two PCA components, with and without whitening to show the effect -- either for the digit data (not much difference) or the face data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout Exercise:\n",
    "\n",
    "### Write a function, plot_faces() [similar to plot_dig()] to plot and label the faces with their correct names. (You may consider expanding the functionality of plot_faces() a bit so that it can label each image with both the correct names and predicted names.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout Exercse: Using this data set (the 7 people, each with at least 70 faces to do face recognition)\n",
    "\n",
    "- ### First do training-testing split :\n",
    "\n",
    "    split the sample (X) into two parts -- X_train and X_test.  For now let X_train be the first 1000 images, and X_test be the rest of the images (288).\n",
    "    \n",
    "    Perform PCA and SVM on X_train.  Then project X_test onto the PCA axes, and then use the trained SVM to predict for X_test.\n",
    "    \n",
    "    This is referred to as \"k-fold.\"  Along with \"leave-one-out\", this is another way to test how good your algorithm is before using it in the \"real world\"\n",
    "\n",
    "    (To connect with what we did for classifying digit image: in classify_dig_svm() from Week15-1, we did a (n-1, 1) split; here we do a train-test split or roughly (3:1), otherwise it's the same.  There the return value is y_pred[0], because there is only one element.  Here's it should just be y_pred since it's an array.)\n",
    "\n",
    "\n",
    "- ### Find the success rate by comparing the prediction for X_test and the correct labels/targets for X_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision vs. Recall\n",
    "\n",
    "### \"The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate.\n",
    "\n",
    "### Precision (P) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$).\n",
    "\n",
    "### $P = \\frac{T_p}{T_p+F_p}$\n",
    "\n",
    "### Recall (R) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$).\n",
    "\n",
    "### $R = \\frac{T_p}{T_p + F_n}$\n",
    "\n",
    "### These quantities are also related to the ($F_1$) score, which is defined as the harmonic mean of precision and recall.\n",
    "\n",
    "### $F1 = 2\\frac{P \\times R}{P+R}$\"\n",
    "\n",
    "\n",
    "### Finally,\n",
    "\n",
    "### \"The support is the number of occurrences of each class in y_true.\"\n",
    "\n",
    "(For more details, see\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "\n",
    "and\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Week15-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
